# AHG_OCR_Pipeline_v2

A modular, realâ€‘time OCR engine built around a **threeâ€‘model ensemble** (EAST, Tesseract, EasyOCR) with a reliabilityâ€‘scored pipeline, asynchronous processing, a custom HUD overlay, and optional voice integration.  
Originally designed for accessibility use cases, the system has evolved into a generalâ€‘purpose **realâ€‘time perception stack** suitable for AR overlays, automation, screen reading, and research.

---

## âœ¨ Key Features

- **Threeâ€‘Model OCR Ensemble**
  - **EAST** for text detection
  - **Tesseract** for classical OCR with dictionary bias
  - **EasyOCR** for deepâ€‘learning recognition
  - Combined using a reliabilityâ€‘scored arbitration system

- **Two Complete Pipelines**
  - **Normal Pipeline** â€” multiâ€‘phase, recursive, reliabilityâ€‘driven
  - **Async Pipeline** â€” threaded, modeâ€‘timed, realâ€‘time screen capture

- **Custom HUD Overlay**
  - Realâ€‘time subtitles and text overlays
  - Themeable rendering layer
  - Designed for ARâ€‘style augmentation

- **Voice Subsystem (Optional)**
  - Voskâ€‘based speech recognition
  - Subtitle engine + punctuation
  - Fully asynchronous

- **Server Layer**
  - HTTP server
  - Camera streaming
  - OCR task orchestration
  - UI templates

- **Extensive Testing Suite**
  - Benchmark images (clear, complex, scene, dummy)
  - PDF samples
  - Live OCR runners
  - Diagnostics + summary tables

---

## ğŸ§© Project Structure

```
app/                Application entrypoints (camera, server, config)
graphics/           HUD overlay, renderer, themes
ocr_modules/        OCR engines, pipelines, preprocessing, scoring
    base_modules/   EAST boxes, preprocess, parsers, reliability
    pipeline_utils/ Async pipeline, modes, phases, race logic
resources/          Models (EAST, Vosk), corpus, frequencies
server_utils/       HTTP server, camera, stream loop, UI templates
shared/             Diagnostics, frame buffers, summaries, helpers
testing/            Images, PDFs, runners, diagnostics, benchmarks
voice/              Async voice engine, recognizer, subtitles
```

---

## ğŸ” Normal OCR Pipeline (Multiâ€‘Model, Reliabilityâ€‘Driven)

The standard pipeline uses all three OCR engines with a multiâ€‘phase flow:

```
EAST + Tesseract
        â†“
EasyOCR + EAST output
        â†“
EasyOCR recursion (if unreliable)
        â†“
Text Output
        â†“
If still unreliable â†’ No Text Output
```

### Reliability Logic
- EAST provides bounding boxes  
- Tesseract provides structured text  
- EasyOCR provides deepâ€‘learning recognition  
- A scoring system determines:
  - **IsReliable** â†’ accept output  
  - **IsNotReliable** â†’ recurse or fail  
- Recursion is bounded by **modeâ€‘based time limits**

Modes:
- `fast` â€” minimal recursion, low latency  
- `steady` â€” balanced  
- `extended` â€” maximum reliability  

---

## âš¡ Async Pipeline (Realâ€‘Time, Threaded)

The async engine is designed for **realâ€‘time screen capture** and runs independently of the main thread.

### Core Behavior
- Converts cv2 â†’ PIL  
- Enforces modeâ€‘based timing (`min_interval`)  
- Uses a `ThreadPoolExecutor`  
- Dispatches frames to `AsyncPipeline`  
- Calls a callback with results  
- Never blocks the main loop  

### Example (simplified)
```python
engine = AsyncOCREngine(mode="steady")

def on_result(result):
    print(result["text"])

engine.process(frame, callback=on_result)
```

This architecture is suitable for:
- AR glasses  
- HUD overlays  
- Desktop screen readers  
- Realâ€‘time automation  
- Continuous monitoring systems  

---

## ğŸ¨ HUD Overlay System

Located in `graphics/`:

- `renderer.py` â€” draws bounding boxes, subtitles, highlights  
- `overlay.py` â€” manages layers and blending  
- `theme.py` â€” colors, fonts, styles  

Designed for:
- realâ€‘time subtitles  
- ARâ€‘style augmentation  
- screen overlays  
- live diagnostics  

---

## ğŸ”Š Voice Subsystem (Optional)

Located in `voice/`:

- Voskâ€‘based speech recognition  
- Async voice engine  
- Subtitle engine  
- Punctuation + cleanup  

Integrates with the HUD for:
- live captions  
- voiceâ€‘driven OCR modes  
- accessibility workflows  

---

## ğŸ§ª Testing & Benchmarking

The `testing/` directory includes:

- **Benchmark_Images** (clear, complex, scene, dummy)
- **PDF samples**
- **Live OCR runners**
- **Diagnostics outputs**
- **Pipeline summaries**
- **OCR race comparisons**
- **Voice tests**

This makes the project suitable for:
- research  
- benchmarking  
- regression testing  
- model comparison  

---

## ğŸš€ Installation

```
pip install -r requirements.txt
```

Models are included in `resources/`:
- `east_model.pb`
- `vosk_model_small/`

---

## â–¶ï¸ Usage

### Run the main application
```
python app/main.py
```

### Run the camera OCR
```
python app/camera_runner.py
```

### Run the server
```
python app/server_runner.py
```

---

## ğŸ§  Why This Project Matters

AHG_OCR_Pipeline_v2 is more than an OCR script.  
Itâ€™s a **modular perception engine** built around:

- multiâ€‘model fusion  
- reliability scoring  
- asynchronous processing  
- realâ€‘time overlays  
- voice integration  
- a complete testing suite  

It can serve as:
- an accessibility tool  
- an AR overlay engine  
- a research platform  
- a realâ€‘time automation module  
- a subsystem of a larger device (e.g., AHGadget)  

---

## ğŸ“œ License

MIT License



